---
title: "Tecnicas de Inferencia"
author: "Carlos Grande Nuñez, Veronica Gomez Gomez y Pablo Olmos Martinez,"
date: "10/20/2019"
output:
  html_document:
    theme: united
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

# ANALISIS DE TECNICAS DE INFERENCIA.

El objetivo de esta practica es analizar las distintas tecnicas de inferencia usadas en clase. Para esta practica hemos usado el siguiente dataset:

https://www.kaggle.com/mishra5001/credit-card

Las librerias usadas son las siguientes:

- sampling
- normtest
- nortest
- data.table

```{r setup, include=FALSE}
library(sampling)
library(normtest)
library(nortest)
library(data.table)

relPath <- getwd()
setwd(relPath)
unzip("credit-card.zip")
base <- read.csv (file="./credit-card/application_data.csv")
names (base)
summary (base)
```

## Informacion general sobre los datos que vamos a usar

Hemos decidido usar unos datos basados en prestamos bancarios, las columnas y datos con los que contamos son los siguientes:

  Variables de tipo discreto:
  
     - Género
     - Flags
     - tipo de casa
     - ORGANIZATION_TYPE
     - OCCUPATION_TYPE
     - NAME_EDUCATION_TYPE   
     - NAME_FAMILY_STATUS 
     - NAME_HOUSING_TYPE
    
  Variables de tipo continuo:
  
     - AMT_INCOME_TOTAL 
     - AMT_CREDIT 
     - AMT_ANNUITY 
     - AMT_GOODS_PRICE
     - edad
     - Antiguedad en el empleo

Antes de comenzar con el resto de ejercicios hemos decidido comprobar si los datos obtenidos nos serviran para el estudio posterior.

```{r InfoGeneral}
table(base$TARGET)
prop.table(table(base$TARGET))
```

Como dato interesante podemos observar que aproximadamente el 8% de los creditos concedidos son impagados

## Ejercicio1: Muestreo del conjunto de datos

Usamos una muestra aleatoria simple de 8403 elementos a la que llamaremos mas. El numero de la muestra mas surge para determinar el tamaño optimo a partir del tamaño poblacional (300k) , un error máximpo de 5000 euros y a un niverl de confianmza del 95% Contamos a su vez con otra muestra de 25 elementos a la que llamaremos mas2.

```{r BusquedaTamIdealMuestra}
set.seed(5876)
baset <- data.table(base)

## Busqueda del tamaño muestral optimo
m1<-mean(base$AMT_INCOME_TOTAL)
m1
dt<-sd(base$AMT_INCOME_TOTAL)
dt
N=307000
B=5000
NS=0.05;NC=1-NS
k=qnorm(1-NS/2);round(k,3)#k=f(z)
#kk=qnorm(1-0.05/2)
s2=(237123)^2
D=B^2/k^2
#formula para el tamano de muestra (cuando se estima la media)
n=(N*s2)/((N-1)*D+s2)
round(n)
```

```{r MuestreoDatos}
mas<-baset[sample(.N, 8403)]
mas2<-baset[sample(.N, 25)]
table(mas$TARGET)
prop.table(table(mas$TARGET))
```

Definimos antes los subsets sobre los que trabajaremos a partir de ahora. Donde t1 (TARGET = 1) corresponde los creditos con impago y t0 (TARGET = 0) corresponde a los creditos pagados

```{r CreacionDeSubsetsTARGET}
#t1 impago
t1<-subset(mas, TARGET=="1")
dim(t1)

#t0 pago
t0<-subset(mas, TARGET=="0")
dim(t0)
```

## Ejercicio2: Caracteristicas interesantes sujetas a estudio

Hemos encontrado las siguientes caracteristicas como intersantes para el estudio:

 - Cuanto es la media del importe de crédito solicitado
 - Cuanto es el ingreso medio de los clientes 
 - ¿Cual es la edad media del cliente que solicita?
 - ¿Cual es la media de la antigüedad en la empresa del cliente medio?
 - Contrastando con el pago/impago del credito


## Ejercicio3: Estimaciones puntuales de las caracteristicas

### Estimacion puntual de la media de los ingresos de los clientes

Ingresos de los clientes cliente, Media Poblacion
```{r MediaPoblacionImporte}
#importe solicitado del cliente Media Poblacion
media.importe=mean(baset$AMT_INCOME_TOTAL)
dt.importe=sd(baset$AMT_INCOME_TOTAL)
media.importe
dt.importe
```

Ingresos de los clientes, Media Muestral
```{r MediaMuestralImporte}
#importe solcitado del cliente Media Muestral
media.importe_mas<-mean(mas$AMT_INCOME_TOTAL)
dt.importe_mas<-sd(mas$AMT_INCOME_TOTAL)
media.importe_mas
dt.importe_mas
```

## Ejercicio4: Intervalo de hipotesis para una de las muestras

### Calculos sobre los ingresos de los clientes con el credito pagado

```{r CalculosIngresosClientesPagado}
#ingresos del cliente TARGET 0
media.ingresos=mean(t0$AMT_INCOME_TOTAL)
media.ingresos
desviacion.ingresos=sd(t0$AMT_INCOME_TOTAL)
desviacion.ingresos

t0_ci=media.ingresos-qnorm(0.95)*desviacion.ingresos/sqrt(length(t0))
t0_cs=media.ingresos+qnorm(0.95)*desviacion.ingresos/sqrt(length(t0))
c(t0_ci,t0_cs)
```

## Ejercicio5: Intervalo de confianza para la comparacion de dicha caracteristica
```{r CalculosIngresosClientesImpagado}
baset0<-subset(base, TARGET=="0")

mean(baset0$AMT_INCOME_TOTAL)

mean(t0$AMT_INCOME_TOTAL)
t0_ci
t0_cs

t.test(t0$AMT_INCOME_TOTAL,mu=168977.2)

```

La media nos da 168977.2 que entra sin problemas en el intervalo de confianza, que va de 154381.4 hasta 183572.9

## Ejercicio6: Contrastes de hipotesis de independencia de las muestras

### Observamos los contrastes de hipotesis de independencia en funcion de los ingresos de la poblacion

```{r AnalisisIngresosPoblacion}
#muestra1 ---Target 0
#muestra2 ---Target 1

###analisis para Ingresos de la poblacion#####

#Ho: Igualdad de Medias en Ingresos para las muestras T0 y T1
#H1: No igualdad...

var.test(x = t0$AMT_INCOME_TOTAL, y = t1$AMT_INCOME_TOTAL )

test <- t.test(t0$AMT_INCOME_TOTAL,t1$AMT_INCOME_TOTAL) # Prueba t de Student
print(test)
# p-value es < 0.05 no podemos Rechazamos la Hipotesis Nula . El valor del estadístico t es muy pequeño
boxplot(t0$AMT_INCOME_TOTAL,t1$AMT_INCOME_TOTAL,names=c("t0","t1"))


#sin outliers parece que nos están mucho más próximos intuitivamente las medias#
##ESTUDIAR QUITAR LOS OUTLIER
boxplot(t0$AMT_INCOME_TOTAL,t1$AMT_INCOME_TOTAL,names=c("t0","t1"),outline=FALSE)
```

Para comparar la media de dos poblaciones a partir de muestras independientes necesitamos saber si la varianza de las dos poblaciones es diferente. Para ello realizamos el F-test, contrasta la hipotesis nula de que dos poblaciones normales tienen la misma varianza. El test no se rechaza ya que no existen diferencias entre las varianzas p-value = 0.475. En caso de que hubiesemos rechazado la hipotesis nula, habriamos tenido que hacer el test de Welch.

Realizamos el test de igualdad de medias.
Rechazamos la hipotesis nula, lo que podemos decir es que a partir de nuestros datos muestrales y en nuestro caso de estudio, la media de los ingresos para la gente que paga o no paga es diferente. Intuitivamente lo podemos ver con el valor de 168977.2 

Nos llama la atencion que el valor del estadistico t no es muy grande t = 3.39 y el valor del p-valor no es demasiado pequeño. A pesar de que el contraste de hipotesis se rechaza, podriamos plantearnos que no cerramos por completo la posibilidad de una investigacion futura.

Tambien nos apoyamos en esta afirmacion con los datos obtenidos en la grafica del boxplot. Nos da que pensar que si hiciesemos un trabajo con los outliars nuestro contraste de hipotesis podria variar.

El siguiente punto seria hacer un trabajo con los outliars y ver despues de este trabajo si el contraste de hipotesis funciona igual o no. 

```{r chisqTest}

#### test chi2
#### Ho : Nivel de Estudios e Impago de Crédito son Independientes
#### H1 : existe dependencia

chisq.test(base$TARGET,base$NAME_EDUCATION_TYPE,correct=FALSE )
chisq.test(base$TARGET,base$NAME_EDUCATION_TYPE)$expected

##Valor del estadistico X2 1019, y el p-value < 2.2e-16 . Rechazamos la Ho
##PARA NUESTRA BASE No existe independencia entre el impago y el Nivel de estudios
## Vamos a sacar una distribucion de datos para ver en frecuencuias cuales son los estudios que más nos impagan
uno<-table (base$NAME_EDUCATION_TYPE,base$TARGET)
prop.table(uno,1)


#### test chi2
#### Ho : Ocupacion e Impago de Crédito son Independientes
#### H1 : existe dependencia


chisq.test(base$TARGET,base$OCCUPATION_TYPE,correct=FALSE )

##Valor del estadistico X2 1975.1, muchos grados de Libertad debido a las muchas profesiones  y el p-value < 2.2e-16 . Rechazamos la Ho
##PARA NUESTRA BASE No existe independencia entre el impago y la profesion
## Vamos a sacar una distribucion de datos para ver en frecuencias cuales son los estudios que más nos impagan
dos<-table (base$OCCUPATION_TYPE,base$TARGET)
prop.table(dos,1)


```

En el caso de la educacion, rechazamos la hipotesis nula de independencia. Se puede decir que existe relacion para nuestros datos entre el nivel de estudios y el impago/pago. Esto es debido a que la diferencia entre la distribucion esperada y la real es muy grande. Lo cual hace que el estadistico chi2 sea muy grande en nuestro caso 1019.

En el caso de la ocupacion, rechazamos la hipotesis nula de independencia, existe relacion significativa entre el impago y la ocupacion. Por ejemplo se puede observar que para la categoria de Accountants tenemos una tasa de impago baja 0.04830327 mientras que para Low-skill Laborers tenemos una tasa de impago de 0.17152413.

## Ejercicio7: Contraste de hipotesis para la caracteristica de estudio de una de las muestras

Vamos a comprobar lo siguiente:

Existen diferencias significativas en el nivel de ingresos entre los clientes que Pagan/Impagan

```{r ContrasteHipotesisPagoImpagoIngresos}

#### test chi2
#### Ho : Nivel de Estudios e Impago de Crédito son Independientes
#### H1 : existe dependencia

chisq.test(mas$TARGET,mas$AMT_INCOME_TOTAL,correct=FALSE )
chisq.test(mas$TARGET,mas$AMT_INCOME_TOTAL)$expected

##Valor del estadistico X2 1019, y el p-value < 2.2e-16 . Rechazamos la Ho 
##PARA NUESTRA BASE No existe independencia entre el impago y el Nivel de estudios
## Vamos a sacar una distribucion de datos para ver en frecuencuias cuales son los estudios que más nos impagan
uno<-table (mas$AMT_INCOME_TOTAL,mas$TARGET)
prop.table(uno,1)
```

Por los resultados obtenidos podemos intuir que aquellos clientes que cuentan con Higher education pagan mejor que aquellos con Lower secondary


## Ejercicio8: Contraste de hipotesis de normalidad para una de las muestras

Este contraste lo efectuaremos sobre la media del importe solicitado

```{r ContrasteMediaImporteSolicitado}

###Prueba de Lilliefors (Kolmogorov-Smirnov)###


lillie.test(log(mas$AMT_INCOME_TOTAL))
histogram(log(mas$AMT_INCOME_TOTAL))
qqnorm(log(mas$AMT_INCOME_TOTAL), pch = 19, col = "gray50") 
qqline(log(mas$AMT_INCOME_TOTAL))


lillie.test(log(t0$AMT_INCOME_TOTAL))
histogram(log(t0$AMT_INCOME_TOTAL))
qqnorm(log(t0$AMT_INCOME_TOTAL), pch = 19, col = "gray50") 
qqline(log(t0$AMT_INCOME_TOTAL))

lillie.test(log(t1$AMT_INCOME_TOTAL))
histogram(log(t1$AMT_INCOME_TOTAL))
qqnorm(log(t1$AMT_INCOME_TOTAL), pch = 19, col = "gray50") 
qqline(log(t1$AMT_INCOME_TOTAL))


ks.test(mas$DAYS_BIRTH, "pnorm", mean(mas$DAYS_BIRTH), sd(mas$AMT_CREDIT))
```

Tras realizar el test de Smirnov y la modificacion del Lilliefors hemos visto que el contraste de normalidad nos devuelve un p-valor muy bajo (2.2e-16). Debido a estos resultado hemos probado a normalizar mediante logaritmo con el mismo resultado. Al tratarse de un contraste tan delicado hemos usado metodos graficos para visualizar la normalidad. Tras comprobar los graficos y aplicar el teorema central del limite, debido al tamaño de nuestra muestra podriamos asumir que es normal.

## Ejercicio9: Contraste de hipotesis para la comparacion de las muestras

TODO 
```{r}

```

